{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUYHXL71HNxx"
   },
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsinsuranceriskassessmentwithmontecarlomethodusingapachespark521-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKJCVZr8y4BP"
   },
   "source": [
    "# **Insurance Risk assessment with Monte Carlo method using Apache Spark**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH9A8WQ76Rcr"
   },
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjCFTdFa6VDH"
   },
   "source": [
    "In this lab, you will learn about Monte Carlo method and calculate the ruin probability of an insurance company using Apache Spark by means of parallel Monte Carlo method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Apb3foqf92Lm"
   },
   "source": [
    "## Prerequisites \n",
    "* Basic Apache Spark knowledge.\n",
    "* Basic Probability theory knowledge.\n",
    "* Basic Python knowledge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsl2a5rr98bZ"
   },
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD3g-zxj9-fe"
   },
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyTW1I04-EBt"
   },
   "source": [
    "* Understand and apply Monte Carlo method.\n",
    "  * Get the basic idea about the accuracy of the method\n",
    "  * Calculate the \"Pi\" number by means of the method\n",
    "  * Parallelize the method using Apache Spark\n",
    "* Understand the Ruin probability of an insurance company.\n",
    "* Calculate the Ruin Probability using Monte Carlo method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPq-2unoUreR"
   },
   "source": [
    "## MONTE CARLO METHOD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLW9AixeNJRD"
   },
   "source": [
    "The idea of the method is quite simple - if you want to estimate the probability of some random event (for example, you are curious about the probability of a coin landing on heads or tails), just repeat your experiment many times (toss the coin). Now, for example, to get the probability of the coin landing on \"obverse\" just divide the number of times you have got \"obverse\" by the total number of tosses. More experiments - more accuracy, due to the law of large numbers.\n",
    "\n",
    "Monte Carlo method was invented in 1930-40 by such bright minds as Enrico Fermi, Stanislav Ulam, and John von Neumann while working on nuclear weapons projects at Los Alamos National Laboratory. The power of the method is that it allows us to calculate probabilities that are difficult or impossible to calculate by other methods. \n",
    "\n",
    "**Useful Links**\n",
    "\n",
    "**Monte-Carlo Method**:  https://en.wikipedia.org/wiki/Monte_Carlo_method\n",
    "\n",
    "**Law of large numbers**:  https://en.wikipedia.org/wiki/Law_of_large_numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdgPJr3SUzXN"
   },
   "source": [
    "## Example 1. Calculating pi value by means of Monte Carlo method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L8W9T4X--xI"
   },
   "source": [
    "Let's do a simple experiment and estimate the value of the pi constant using Monte-Carlo method. The idea is simple - we draw a unit square with an inner circle and then generate a large number of random points uniformly distributed within the square. \t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjEj-ap566UO"
   },
   "source": [
    "<left>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/insurance-risk-assessment-with-montecarlo-method-using-apache-spark/images/circle.jpg\" width=\"500\" alt=\"MC Pi sampling\">\n",
    "</left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ3azdXrLty3"
   },
   "source": [
    "Now let's see, how it works!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJg33OhSEK26"
   },
   "source": [
    " $\\frac{{Surface\\;of\\;the\\;circle}}{{Surface\\;of\\;the\\;square}} \\approx \\frac{{Number\\;of\\; points\\; in\\; the\\; circle}}{{Total\\; number\\; of\\; points}} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4FA-3682OYE"
   },
   "source": [
    "Knowing that the surface of the circle is $\\pi*R^2$ and the radius of our circle is $R=0.5$ we get $\\pi \\approx 4 \\frac{{Number\\;of\\; points\\; in\\; the\\; circle}}{{Total\\; number\\; of\\; points}} $  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh9VD3nzEPt5"
   },
   "source": [
    "The error, according to HÃ¶effding inequality, is proportional to $\\frac{{1}}{{\\sqrt{Total\\; number\\; of\\; points}}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D29M_Nk4SfGq"
   },
   "source": [
    "Importing libraries, setting constants.\n",
    "\n",
    "**Library documentation** https://docs.python.org/3/library/random.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ar3KRIssScHa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random   \n",
    "N = 1000000 #Total number of points generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcdWUyddUBjs"
   },
   "source": [
    "Now, let's start our simulations. Please replace ##YOUR CODE GOES HERE## with your code. Your goal is to check if our randomly generated point with (x,y) coordinates is in the circle with radius R=1 and the center at (0,0). Hint: use the Pythagorean Theorem.\n",
    "\n",
    "**Pythagorean Theorem** https://en.wikipedia.org/wiki/Pythagorean_theorem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NWmdhuW6-9sb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate value of Pi is  3.14084\n"
     ]
    }
   ],
   "source": [
    "bingo = 0 # Number of points in the circle\n",
    "\n",
    "for i in range(N):\n",
    "  # Generate the coortidates of the point with uniform distribution within the square. \n",
    "    x= random.uniform(-0.5, 0.5)\n",
    "    y= random.uniform(-0.5, 0.5)\n",
    "  \n",
    "    # Checking if we've hit the circle (hint: use Pythagorean Theorem)\n",
    "    if (x**2 + y**2)<= 0.25:\n",
    "        bingo+= 1 # Bingo! We did it!\n",
    "  \n",
    "    # Estimating value of pi,\n",
    "    pi = 4* bingo/N\n",
    "\n",
    "  \n",
    "print(\"Approximate value of Pi is \", pi)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGt4-T_pVGkt"
   },
   "source": [
    "## RUIN PROBABILITY CALCULATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fvi3Onu5VRhj"
   },
   "source": [
    "Now let's do some serious stuff and calculate the ruin probability of an insurance company, modeled by the Classical Risk Process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSBO94jlEjYU"
   },
   "source": [
    "## The Classical Risk Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLe856dJLqGn"
   },
   "source": [
    "The Classical Risk Process describes an insurance company with an initial capital $u$ through incoming cash premiums and outgoing claims. Premiums arrive at a constant rate $c>0$ and claims are random values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Di7lTpGTPmGF"
   },
   "source": [
    "<left>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/insurance-risk-assessment-with-montecarlo-method-using-apache-spark/images/RiskProcess.JPG\" width=\"500\" alt=\"Classical Risk Process\">\n",
    "</left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dub44TR8Lj6O"
   },
   "source": [
    " ${\\xi _t} = u + ct - \\sum\\nolimits_{k = 1}^{{N_t}} {{z_k}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzgkxnLZK4fG"
   },
   "source": [
    "where  ${\\xi _t}$ is the capital of the insurance company at the time moment $t$ .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOWxSGQ2MA_6"
   },
   "source": [
    "The sum of insurance claims ${{z_k}}$ that  arrive according to a Poisson process $N_{t}$ with intensity $\\lambda$ before the time moment  $t$ and are independent and identically distributed non-negative random variables (for simplicity, we consider an exponentially distributed claim size with a positive mean).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUZ1Nd5_MqTk"
   },
   "source": [
    "Now we will calculate the Ruin Probability of the company on the finite time interval with crude Monte Carlo method. To do this, we will simulate random trajectories and calculate the fraction of those leading the company to ruin (capital turned negative). \n",
    "\n",
    "**Ruin Theory** https://en.wikipedia.org/wiki/Ruin_theory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWj_Jv7HdnLB"
   },
   "source": [
    "## Initialization/loading Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DtNeLPQjhTZu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  added / updated specs:\n",
      "    - pyspark\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.12.12 |       h06a4308_0         126 KB\n",
      "    certifi-2022.12.7          |   py37h06a4308_0         150 KB\n",
      "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
      "    py4j-0.10.7                |           py37_0         241 KB\n",
      "    pyspark-2.4.5              |             py_0       198.8 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       203.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  py4j               pkgs/main/linux-64::py4j-0.10.7-py37_0 \n",
      "  pyspark            pkgs/main/noarch::pyspark-2.4.5-py_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2023.5.7~ --> pkgs/main::ca-certificates-2023.12.12-h06a4308_0 \n",
      "  openssl            conda-forge::openssl-1.1.1t-h0b41bf4_0 --> pkgs/main::openssl-1.1.1w-h7f8727e_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            conda-forge/noarch::certifi-2023.5.7-~ --> pkgs/main/linux-64::certifi-2022.12.7-py37h06a4308_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pyspark-2.4.5        | 198.8 MB  |                                       |   0% \n",
      "certifi-2022.12.7    | 150 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "py4j-0.10.7          | 241 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 126 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.7 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "py4j-0.10.7          | 241 KB    | ##4                                   |   7% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1w       | 3.7 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pyspark-2.4.5        | 198.8 MB  |                                       |   0% \u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 126 KB    | ####7                                 |  13% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pyspark-2.4.5        | 198.8 MB  | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pyspark-2.4.5        | 198.8 MB  | 3                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 126 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 126 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "certifi-2022.12.7    | 150 KB    | ##################################### | 100% \u001b[A\n",
      "certifi-2022.12.7    | 150 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pyspark-2.4.5        | 198.8 MB  | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "py4j-0.10.7          | 241 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "pyspark-2.4.5        | 198.8 MB  | ##3                                   |   6% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "D9mBmdZ7hTZv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError as e:\n",
    "    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mdGO3tdwhTZw",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/26 02:46:21 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQJC1x5oNz6k"
   },
   "source": [
    "## CALCULATIONS FOR CLASSICAL RISK PROCESS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HT2MBkCD3pJ"
   },
   "source": [
    "**MODEL PARAMETERS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuBO7Cl0ifaP"
   },
   "source": [
    "We consider risk process with INITIAL_CAPITAL, with premium arrive at a constant INCOME_INTENSITY rate, claims are independent and identically distributed non-negative random variables (here we consider an exponentially distributed claim size with a positive CLAIM_MEAN) and arrive according to a Poisson process with INCOME_INTENSITY rate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0idPZJOAzOUw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "INITIAL_CAPITAL = 10  # initial capital\n",
    "MAXTIME = 10          # simulation period\n",
    "INCOME_INTENSITY = 1  # income intensity per time unit\n",
    "CLAIM_INTENSITY = 1   # time between claims is expontntialy distributed \n",
    "CLAIM_MEAN = 1        # claims are exponentialy distributed with CLAIM MEAN, should be >0\n",
    "TRAJEC_NUM = 1000      # number of trajectories simulated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5E3MA4UOfwu"
   },
   "source": [
    "**THE MODEL**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfTz1MUbs4lp"
   },
   "source": [
    "Now let's set up our model. Please, define the capital variation by replacing ##YOUR CODE GOES HERE## with your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bau_E7BwzBeQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from operator import add\n",
    "\n",
    "def bankrupcy(seed):\n",
    "    random.seed(seed)\n",
    "    capital = INITIAL_CAPITAL\n",
    "    time = 0\n",
    "    while (time < MAXTIME)and(capital>=0):\n",
    "      time_step=random.expovariate(CLAIM_INTENSITY)\n",
    "      time+=time_step\n",
    "      capital += INCOME_INTENSITY * time_step - random.expovariate(1/CLAIM_MEAN)\n",
    "    if (capital<0):\n",
    "      return 1 \n",
    "    else: \n",
    "      return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_7BhI26kEHH"
   },
   "source": [
    "**CALCULATIONS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xudP4648OVVk"
   },
   "source": [
    "Using Apache Spark parallelization for massive trajectories simulation.\n",
    "\n",
    "**Parallelize method:** https://sparkbyexamples.com/pyspark/pyspark-parallelize-create-rdd/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WKhjYU9izwpn",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our company will bunkrupt with 0.039 probability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ruin_probability =sc.parallelize([time.time() + i for i in range(TRAJEC_NUM)]).map(bankrupcy).reduce(add)/TRAJEC_NUM\n",
    "print(\"Our company will bunkrupt with\", ruin_probability, \"probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ce7net1N7s0t"
   },
   "source": [
    "**CONCLUSIONS**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inGnQFrZ7342"
   },
   "source": [
    "Now, when you are familiar with Monte Carlo method, please do not forget that the main feature of this method is that you can apply it to any Generalized Risk Process you need, with no limits at all. Non-linear income, non-Poisson claim arrival, dividend withdrawal, discreet time, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_gOiFZt9ckW"
   },
   "source": [
    "**Example of Generalized Risk Process**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEwpJ8kl9UME"
   },
   "source": [
    "<left>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/insurance-risk-assessment-with-montecarlo-method-using-apache-spark/images/GRiskProcess.JPG\" width=\"500\" alt=\"Generalized Risk Process\">\n",
    "</left>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-3v_XPzSw3t"
   },
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJLreu9ITNNO"
   },
   "source": [
    "[Bogdan Norkin](https://www.researchgate.net/profile/Bogdan-Norkin?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsinsuranceriskassessmentwithmontecarlomethodusingapachespark521-2023-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0UYEduOTjM9"
   },
   "source": [
    "Copyright &copy; 2021 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsinsuranceriskassessmentwithmontecarlomethodusingapachespark521-2023-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
